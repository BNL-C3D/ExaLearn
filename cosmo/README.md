# Cosmology with Deep Learning
Author : Yihui (Ray) Ren
email  : yren@bnl.gov

## Introduction

Running cosmology simulations is a time consuming task.
This work is to explore the opportunities to improve this condition.

The simulation tools we are using are:

1. [MUSIC](https://www-n.oca.eu/ohahn/MUSIC/) for generating grid initial
   conditions for high-resolution cosmological simulations.
1. [PyCola](https://bitbucket.org/tassev/pycola/src/default/) for evolving the
   universe using the comoving Lagrangian Acceleration (COLA) method.

The work flow consists of two major parts: 

1. Data Preparation:
    1. Generate initial conditions using MUSIC.
    1. Evolve the universe using PyCola given an initial condition.
    1. Calculate the 3D galaxy density (3d-histogram) and divide it into 8 sub-volumes.
1. Model Training:
    1. Create PyTorch Dataset for training deep learning models.
    1. Using various 3D-CNN models to predict the cosmological parameters.
    1. And more (in future)

## Usage

### Data Preparation
There are several python scripts in the `./src/` folder to perform various tasks in the data preparation procedure.

**`gen_music_cfg.py`** will generate a configuration file for the MUSIC program.
```
usage: gen_music_cfg.py [-h] -o OUTPUT_FILE -m [0.15,0.45) -w [-1.2, -0.8] -s
                        [0.5,1.0] [--rand_seed RAND_SEED]

required arguments:
  -o OUTPUT_FILE, --output_file OUTPUT_FILE
                        output file as MUSIC config file
  -m [0.15,0.45), --omega_m [0.15,0.45)
                        Omega-M
  -w [-1.2, -0.8], --w0 [-1.2, -0.8]
                        w0
  -s [0.5,1.0], --sigma8 [0.5,1.0]
                        Sigma8

optional arguments:
  --rand_seed RAND_SEED
                        random seed
```

**`pycola_evolve.py`** will run the PyCola simulation using the initial
condition generated by the MUSIC program. Note that, this requires to run under
pycola virtual env. 

```
usage: pycola_evolve.py [-h] -i INPUT_FILE -o OUTPUT_FILE -b BOX_LENGTH -l
                        LEVEL [-g GRID_SCALE]

required arguments:
  -i INPUT_FILE, --input_file INPUT_FILE
                        input hdf5 file from MUSIC
  -o OUTPUT_FILE, --output_file OUTPUT_FILE
                        output file in npz format
  -b BOX_LENGTH, --box-length BOX_LENGTH
                        box length
  -l LEVEL, --level LEVEL
                        level

optional arguments:
  -g GRID_SCALE, --grid-scale GRID_SCALE
                        set grid scale [=3]
```


**`hist_nbody.py`** will calculate the 3D density from the PyCola output (3D
coordinates of the galaxies).  
```
usage: hist_nbody.py [-h] -i INPUT_FILE -o OUTPUT_FILE [-b BOX_LENGTH]
                     [-n NBINS]

required arguments:
  -i INPUT_FILE, --input_file INPUT_FILE
                        input 3D volume in npz format
  -o OUTPUT_FILE, --output_file OUTPUT_FILE
                        output 3D histograms in npz format

optional arguments:
  -b BOX_LENGTH, --box_length BOX_LENGTH
                        box length [=512]
  -n NBINS, --nbins NBINS
                        number of bins [=256]
```

**`./run.py`** will run all three procedures above and MUSIC in sequence. 
Note that, the `example.slurm` provides an example on how to submit the job on
HPC clusters. (One needs to modify the script accordingly.) The end results are in numpy data format `*.npy`.
```
usage: run.py [-h] -m [0.15,0.45) -w [-1.2, -0.8] -s [0.5,1.0]
              [--rand_seed RAND_SEED] [-v]

required arguments:
  -m [0.15,0.45), --omega_m [0.15,0.45)
                        Omega-M
  -w [-1.2, -0.8], --w0 [-1.2, -0.8]
                        w0
  -s [0.5,1.0], --sigma8 [0.5,1.0]
                        Sigma8

optional arguments:
  --rand_seed RAND_SEED
                        random seed
  -v, --verbosity
```

### Training Deep Learning Models
We use the 



## Install 

* conda env
* fftw
* MUSIC
* PyCola

## MUSIC
generate initial conditions.


* change random seed
* change cosmological parameters
    -   Omega-m [0.15, 0.45)
    -   Omega-L (:= 1-Omega-m)
    -   sigma_8 [0.5, 1.0]   
* change output file name
* output a `*.hdf5` file

## PyCola

* `02_evolve.py`, use the initial condition MUSIC generated.
    -   `python2 ./02_evolve.py -i ../MUSIC/peter_ics_bl_512.hdf5 -o ./peter_ics_bl_512.npz -b  512 -l 9 -g 3`
* `03_hist_nbody.py`, generates the 3D histogram from the particles.
    -   `python 03_hist_nbody.py -i peter_ics_bl_512.npz -o peter_ics_hist.npz -n 256 -b 512`

## Setup Conda Environment in HPC clusters

Usually HPC clusters have `anaconda2/3` module. To see if it is there, `$ module avail`. 
Then, to load the `anaconda3`: `$ module load anaconda3`

* create pycola conda environment `conda env create -f pycola_env.yml`
* `cd music; make; cd ..`
* `cd pycola; python setup.py build_ext --inplace`

## TODO

[ ] workflow
[ ] consistent dir structure
[ ] gen batch of data given cosmological parameters.

## Troubleshoot
### Install MUSIC
* If cannot find hd5.h file, edit the CONDA env in Makefile
* If cannot find fftw3, 
    - install it from scratch

```
    wget http://www.fftw.org/fftw-3.3.8.tar.gz
    ./configure --enable-openmp --enable-float
    make install
```
    - try to allocate it using `ldconfig -v | grep fftw3`

## References
[CosmoFlow](https://arxiv.org/abs/1808.04728)
[CosmoGAN](https://arxiv.org/abs/1706.02390)
[NERSC:cosmoflow-sims](https://github.com/NERSC/cosmoflow-sims)
